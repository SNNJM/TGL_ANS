{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Solution Architecture"
      ],
      "metadata": {
        "id": "WCjA1MPZS8H6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "[PDF Files Input] → Google Colab Environment\n",
        "            ↓\n",
        "┌───────────────────────────────────────────────┐\n",
        "│ PDF Processing Pipeline                       │\n",
        "│ ├─ Extract Text (pdfplumber)                  │\n",
        "│ ├─ Extract Tables (pdfplumber + pandas)       │\n",
        "│ └─ OCR Images (EasyOCR + PIL)                 │\n",
        "└───────────────────────────┬───────────────────┘\n",
        "                            ↓\n",
        "┌───────────────────────────────────────────────┐\n",
        "│ Extraction & Consolidation Logic              │\n",
        "│ ├─ Identify Document Type (regex patterns)    │\n",
        "│ ├─ Extract Consignor Information (regex)      │\n",
        "│ ├─ Extract References & Containers (regex)    │\n",
        "│ └─ Extract Dates & Times (regex)              │\n",
        "└───────────────────────────┬───────────────────┘\n",
        "                            ↓\n",
        "┌───────────────────────────────────────────────┐\n",
        "│ Shipment Consolidation                        │\n",
        "│ └─ Organize into Structured Shipment Data     │\n",
        "└───────────────────────────┬───────────────────┘\n",
        "                            ↓\n",
        "┌───────────────────────────────────────────────┐\n",
        "│ Query & Display Interface                     │\n",
        "│ └─ Interactive Query:                         │\n",
        "│    \"How many shipments are currently tracked?\"│\n",
        "└───────────────────────────────────────────────┘\n",
        "```\n"
      ],
      "metadata": {
        "id": "jDxGPLugamw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "[ Google Colab Notebook ]\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ [ PDF Documents Directory: /content/data/ ]                     │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ PDF Document Processing                                         │\n",
        "│   ├── pdfplumber (extract text & tables from PDF pages)         │\n",
        "│   ├── EasyOCR (text extraction from images of PDF pages)        │\n",
        "│   └── PIL (generate and handle images from PDF pages)           │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ Consolidated Document Text                                      │\n",
        "│   └── Raw text from PDF pages, OCR text                         │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ Information Extraction (Regex-based)                            │\n",
        "│   ├── Consignor                                                 │\n",
        "│   ├── Ocean Bill of Lading (Reference number)                   │\n",
        "│   ├── Container number                                          │\n",
        "│   ├── Dates (ETD, ETA, ATD, ATA)                                │\n",
        "│   └── Delivered (JobDate and Time Delivered)                    │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ Shipments Data Consolidation                                    │\n",
        "│   ├── defaultdict-based grouping by Consignor                   │\n",
        "│   └── Classified by document types (PreAlert, NOA, POD)         │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ RAG Integration (Vector DB & Retrieval)                         │\n",
        "│   ├── LangChain Document objects                                │\n",
        "│   ├── RecursiveCharacterTextSplitter (Text chunking)            │\n",
        "│   ├── SentenceTransformerEmbeddings (Embeddings generation)     │\n",
        "│   └── FAISS Vectorstore (Semantic search & indexing)            │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ Query Handling                                                  │\n",
        "│   ├── Natural Language Queries                                  │\n",
        "│   └── Semantic Retrieval (LangChain RAG)   │\n",
        "└─────────────┬───────────────────────────────────────────────────┘\n",
        "              ↓\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│ Results Display                                                 │\n",
        "│   └── Console/Text-based summary of extracted shipment details  │\n",
        "│       per consignor and shipment type                           │\n",
        "└─────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "OjjEtgrTUDf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to run this Colab\n",
        "\n",
        "1. Create a folder name data (the location would be /content/data)\n",
        "2. Upload the shipping pdfs into it\n",
        "3. set runtime to T4 GPU with high RAM and connect\n",
        "4. Run the cells below"
      ],
      "metadata": {
        "id": "MoSDJ1S3X1_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required libraries"
      ],
      "metadata": {
        "id": "Wk4qMt7VQ6en"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3L7ohjvQC4c",
        "outputId": "587d7bbf-8cd1-46bc-ba3f-b32cfe190ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m335.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet\\\n",
        "  pdfplumber \\\n",
        "  easyocr \\\n",
        "  pillow \\\n",
        "  pandas \\\n",
        "  langchain \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu \\\n",
        "  torch \\\n",
        "  langchain-community\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "E3e0AFocQ1nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pdfplumber\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from langchain.docstore.document import Document\n"
      ],
      "metadata": {
        "id": "R_mH1DtEQ1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "7LSctJjQRQRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PDF_DIRECTORY = \"/content/data/\""
      ],
      "metadata": {
        "id": "GBfIUinnRTN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "9wcty6emWq11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_doc_type(filename):\n",
        "    n = filename.lower().replace('_','').replace('-','')\n",
        "    if \"prealert\" in n: return \"PreAlert\"\n",
        "    if \"noa\" in n: return \"NOA\"\n",
        "    if \"pod\" in n: return \"POD\"\n",
        "    return \"Other\"\n",
        "\n",
        "def extract_reference_and_container(text):\n",
        "    reference = None\n",
        "    container = None\n",
        "    ocean = re.search(r'Ocean Bill of Lading[:\\s]*([A-Z0-9\\-]*\\d+[A-Z0-9\\-]*)', text, re.IGNORECASE)\n",
        "    if ocean:\n",
        "        reference = ocean.group(1).strip()\n",
        "    else:\n",
        "        generic = re.search(\n",
        "            r'(?:Reference|B/L[- ]?NO|BILL OF LADING)[:\\.\\s]*([A-Z0-9]*\\d+[A-Z0-9\\-]*)',\n",
        "            text, re.IGNORECASE\n",
        "        )\n",
        "        if generic:\n",
        "            reference = generic.group(1).strip()\n",
        "    cont = re.search(r'Container[#:\\s]*([A-Z0-9]*\\d+[A-Z0-9]*)', text, re.IGNORECASE)\n",
        "    if cont:\n",
        "        container = cont.group(1).strip()\n",
        "    return reference, container\n",
        "\n",
        "def extract_consignor(text):\n",
        "    lines = text.splitlines()\n",
        "    for idx, line in enumerate(lines):\n",
        "        if re.match(r'^\\s*PICKUP\\b', line, re.IGNORECASE):\n",
        "            for j in range(idx+1, len(lines)):\n",
        "                nxt = lines[j].strip()\n",
        "                if nxt:\n",
        "                    return nxt\n",
        "    m = re.search(r'(?:Consignor|Shipper|Client Name)\\s*[:\\-]\\s*([A-Za-z0-9 &,.()]+)', text, re.IGNORECASE)\n",
        "    if m:\n",
        "        return m.group(1).strip()\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(r'^\\s*CONSIGNOR\\b', line, re.IGNORECASE):\n",
        "            for j in range(i+1, len(lines)):\n",
        "                l = lines[j].strip()\n",
        "                if l:\n",
        "                    return l.split(',')[0].strip()\n",
        "    for line in lines:\n",
        "        l = line.strip()\n",
        "        if not l or re.match(r'^(INVOICES? &? DOCS?|PAGE|POD|NOA|PreAlert|Shipment)', l, re.IGNORECASE) or len(l) < 3:\n",
        "            continue\n",
        "        return l\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "def extract_date_time_fields(text, doc_type):\n",
        "    date_rx = r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}'\n",
        "    time_rx = r'\\d{1,2}:\\d{2}(?::\\d{2})?(?:\\s*[APMapm]{2})?'\n",
        "    etd = eta = atd = ata = \"N/A\"\n",
        "    dd = dt = \"N/A\"\n",
        "    if doc_type == \"PreAlert\":\n",
        "        m1 = re.search(rf'ETD[:\\s]*({date_rx})', text)\n",
        "        m2 = re.search(rf'ETA[:\\s]*({date_rx})', text)\n",
        "        etd = m1.group(1) if m1 else etd\n",
        "        eta = m2.group(1) if m2 else eta\n",
        "    elif doc_type == \"NOA\":\n",
        "        m = re.search(rf'ETA[:\\s]*({date_rx})', text)\n",
        "        eta = m.group(1) if m else eta\n",
        "    else:\n",
        "        m3 = re.search(rf'ATD[:\\s]*({date_rx})', text)\n",
        "        m4 = re.search(rf'ATA[:\\s]*({date_rx})', text)\n",
        "        atd = m3.group(1) if m3 else atd\n",
        "        ata = m4.group(1) if m4 else ata\n",
        "        m5 = re.search(rf'Delivered.*?({date_rx}).*?(?:at)?\\s*({time_rx})?', text, re.IGNORECASE|re.DOTALL)\n",
        "        if m5:\n",
        "            dd = m5.group(1)\n",
        "            dt = m5.group(2) or dt\n",
        "    return etd, eta, atd, ata, dd, dt"
      ],
      "metadata": {
        "id": "bAVS7vGIWueh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCR - EasyOCR"
      ],
      "metadata": {
        "id": "-wU_39bqWJeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initialize EasyOCR ---\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "# --- Extract Text + Tables + OCR from PDFs ---\n",
        "def extract_text_from_pdfs_in_directory(directory_path):\n",
        "    all_raw_texts, filenames = [], []\n",
        "    pdf_files = [f for f in os.listdir(directory_path) if f.lower().endswith('.pdf')]\n",
        "    if not pdf_files:\n",
        "        print(f\"No PDF files found in {directory_path}.\")\n",
        "        return [], []\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            pdf_path = os.path.join(directory_path, pdf_file)\n",
        "            pages_text = []\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    txt = page.extract_text() or \"\"\n",
        "                    pages_text.append(txt)\n",
        "                    for table in page.extract_tables():\n",
        "                        if table:\n",
        "                            df = pd.DataFrame(table[1:], columns=table[0]) if table[0] else pd.DataFrame(table)\n",
        "                            pages_text.append(df.to_csv(index=False))\n",
        "                    img = page.to_image(resolution=300).original\n",
        "                    tmp = f\"/tmp/{pdf_file}-{page.page_number}.png\"\n",
        "                    img.save(tmp)\n",
        "                    ocr = reader.readtext(tmp, detail=0)\n",
        "                    os.remove(tmp)\n",
        "                    if ocr:\n",
        "                        pages_text.append(\" \".join(ocr))\n",
        "            all_raw_texts.append(\"\\n\".join(pages_text))\n",
        "            filenames.append(pdf_file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {pdf_file}: {e}\")\n",
        "    return all_raw_texts, filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxuoJJ0IWEKZ",
        "outputId": "4fa2b068-4a69-46f7-db9b-6a2c17a6fd24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Formatting"
      ],
      "metadata": {
        "id": "bGoTVBRaXWXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def consolidate_shipments(docs):\n",
        "    shipments = defaultdict(lambda: defaultdict(dict))\n",
        "    for doc in docs:\n",
        "        ref, cont = extract_reference_and_container(doc.page_content)\n",
        "        consignor = extract_consignor(doc.page_content)\n",
        "        doc_type = extract_doc_type(doc.metadata.get('source',''))\n",
        "        etd, eta, atd, ata, dd, dt = extract_date_time_fields(doc.page_content, doc_type)\n",
        "        key = ref or cont or doc.metadata.get('source','unknown_shipment')\n",
        "        shipments[consignor][key][doc_type] = {\n",
        "            'reference': ref or 'N/A',\n",
        "            'container': cont or 'N/A',\n",
        "            'etd': etd,\n",
        "            'eta': eta,\n",
        "            'atd': atd,\n",
        "            'ata': ata,\n",
        "            'delivered_date': dd,\n",
        "            'delivered_time': dt\n",
        "        }\n",
        "    return shipments\n",
        "\n",
        "def display_all_shipments(shipments):\n",
        "    for consignor, groups in shipments.items():\n",
        "        first_type = next(iter(next(iter(groups.values())).keys()))\n",
        "        print(f\"I found {len(groups)} shipments FOR {consignor}  (from {first_type})\")\n",
        "        for i, (shipment_key, parts) in enumerate(groups.items(), 1):\n",
        "            data = parts[next(iter(parts))]\n",
        "            print(f\"           Shipment{i}:  Reference: {data['reference']}  \")\n",
        "            print(f\"                         Estimate Departing:  {data['etd']}  \")\n",
        "            print(f\"                         Estimate Arriving:  {data['eta']}  \")\n",
        "            print(f\"                         Actual Departing: {data['atd']}\")\n",
        "            print(f\"                         Actual Arriving: {data['ata']}    \")\n",
        "            print(f\"                         Container#:  {data['container']}  \")\n",
        "            print(f\"                         Delivered: {data['delivered_date']} at {data['delivered_time']}  \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OdCDQxNdWWMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main operations"
      ],
      "metadata": {
        "id": "XHFGdpx8Xe7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts, files = extract_text_from_pdfs_in_directory(PDF_DIRECTORY)\n",
        "docs = [Document(page_content=text, metadata={'source':filename}) for text, filename in zip(texts, files)]\n",
        "shipments = consolidate_shipments(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37IiIJuDXZRq",
        "outputId": "4cce321e-847e-4e05-da93-6924268d2870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
            "WARNING:pdfminer.pdffont:Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query"
      ],
      "metadata": {
        "id": "YJCv_PIIXlPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How many shipments are currently tracked?\"\n",
        "if \"how many\" in query.lower() and \"shipment\" in query.lower():\n",
        "    display_all_shipments(shipments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2AzbV8QXjvn",
        "outputId": "020445b4-0d2f-4d80-ca78-fae912214cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I found 1 shipments FOR TAX INVOICE MEDITERRANEAN SHIPPING COMPANY(AUST) PTY LIMITED  (from POD)\n",
            "           Shipment1:  Reference: HDMUSHAZ03315800  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 2 shipments FOR SOUTH PACIFIC LOGISTICS CO.,LTD  (from PreAlert)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "           Shipment2:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 1 shipments FOR CDE INTERNATIONAL MAREE DOWNEY  (from PreAlert)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 2 shipments FOR ANL SINGAPORE PTE LTD  (from NOA)\n",
            "           Shipment1:  Reference: HDMUSHAZ03315800  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "           Shipment2:  Reference: AMG0150149  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 2 shipments FOR Location TGL WAREHOUSE  (from POD)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: 15/11/2024 at N/A  \n",
            "\n",
            "           Shipment2:  Reference: FBA15F9GLD8R  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: 18/11/2024 at N/A  \n",
            "\n",
            "I found 1 shipments FOR Location CNC  (from POD)\n",
            "           Shipment1:  Reference: 2020907  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: 20/11/2024 at N/A  \n",
            "\n",
            "I found 1 shipments FOR Pickup depot 1 juile TGL No signature found n/a  (from POD)\n",
            "           Shipment1:  Reference: ALK0444644  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: 19/11/2024 at 10:42  \n",
            "\n",
            "I found 2 shipments FOR ABC INTERNATIONAL (SHANGHAI) CO.  (from PreAlert)\n",
            "           Shipment1:  Reference: OOLU2734921070  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "           Shipment2:  Reference: OOLU2735833830  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 1 shipments FOR CDE INTERNATIONAL THINK GLOBAL LOGISTICS PTY LTD  (from PreAlert)\n",
            "           Shipment1:  Reference: HDMUSHAZ03315800  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 1 shipments FOR LOGISBER FORWARDING SL HOSPITALET DE LLOBREGAT SPAIN  (from NOA)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 1 shipments FOR FLEXPORT INTERNATIONAL DISTRICT CHINA  (from NOA)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 1 shipments FOR FLEXPORT INTERNATIONAL ROAD, JINGAN DISTRICT,  (from NOA)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  N/A  \n",
            "                         Estimate Arriving:  N/A  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n",
            "I found 1 shipments FOR INFINITY CARGO EXPRESS LIMITED Issue Date  (from PreAlert)\n",
            "           Shipment1:  Reference: N/A  \n",
            "                         Estimate Departing:  09/04/25  \n",
            "                         Estimate Arriving:  24/04/25  \n",
            "                         Actual Departing: N/A\n",
            "                         Actual Arriving: N/A    \n",
            "                         Container#:  N/A  \n",
            "                         Delivered: N/A at N/A  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhhopUmtYZZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}